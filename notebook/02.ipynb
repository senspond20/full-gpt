{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Parser\n",
    "> LLM 의 응답을 변형해야 하는 경우가 있을때 유용하게 사용할 수 있다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "# BaseOutputParser 을 상속받아서 구현\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    \n",
    "    \"\"\" parse 메소드를 반드시 정의해줘야 한다\n",
    "        Can't instantiate abstract class CommaOutputParser with abstract method parse'\n",
    "    \"\"\"\n",
    "    def parse(self, text):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banana ', 'apple', 'donut']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = CommaOutputParser()\n",
    "p.parse(\"banana ,apple,donut\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseOutputParser 을 상속받아서 구현\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items)) # items 의 요소들의 좌우공백도 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banana', 'apple', 'donut']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = CommaOutputParser()\n",
    "p.parse(\"banana ,apple,donut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OutputParser 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1. Mercury\\n2. Venus\\n3. Earth\\n4. Mars\\n5. Jupiter\\n6. Saturn\\n7. Uranus\\n8. Neptune\\n9. Pluto (dwarf planet)\\n10. Eris (dwarf planet)'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template1 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be asnwered with a list of max {max_items}. DO NOT reply with anything else\")\n",
    "    ,\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "prompt = template1.format_messages(max_items = 10, question = \"What are the Planets?\")\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='mercury, venus, earth, mars, jupiter, saturn, uranus, neptune'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are with a comma separated list generating machine. \n",
    "     Everything you are asked will be asnwered with a list of max {max_items} in lowercase. \n",
    "     DO NOT reply with anything else\"\"\")\n",
    "    ,\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "prompt = template2.format_messages(max_items = 10, question = \"What are the Planets?\")\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = CommaOutputParser()\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain - LCEL(LangChain Expand Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template2 | chat | CommaOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu',\n",
       " 'charmander',\n",
       " 'squirtle',\n",
       " 'bulbasaur',\n",
       " 'jigglypuff',\n",
       " 'eevee',\n",
       " 'meowth',\n",
       " 'snorlax',\n",
       " 'magikarp']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"max_items\" :  10,\n",
    "    \"question\" : \"What are poketmon?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'orange',\n",
       " 'yellow',\n",
       " 'green',\n",
       " 'blue',\n",
       " 'indigo',\n",
       " 'violet',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'brown',\n",
       " 'black',\n",
       " 'white',\n",
       " 'gray',\n",
       " 'silver',\n",
       " 'gold',\n",
       " 'beige',\n",
       " 'cream',\n",
       " 'maroon',\n",
       " 'navy',\n",
       " 'teal',\n",
       " 'turquoise',\n",
       " 'lavender',\n",
       " 'magenta',\n",
       " 'coral',\n",
       " 'peach',\n",
       " 'mint',\n",
       " 'olive',\n",
       " 'mustard',\n",
       " 'plum',\n",
       " 'mauve',\n",
       " 'fuchsia',\n",
       " 'cyan',\n",
       " 'ivory',\n",
       " 'charcoal',\n",
       " 'tan',\n",
       " 'slate',\n",
       " 'khaki',\n",
       " 'rust',\n",
       " 'periwinkle',\n",
       " 'sage',\n",
       " 'brick',\n",
       " 'cobalt',\n",
       " 'pewter',\n",
       " 'moss',\n",
       " 'champagne']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"max_items\" :  50,\n",
    "    \"question\" : \"What are color?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['power',\n",
       " 'ambition',\n",
       " 'empire',\n",
       " 'greatness',\n",
       " 'war',\n",
       " 'defeat',\n",
       " 'strategy',\n",
       " 'leadership',\n",
       " 'legacy',\n",
       " 'France']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"max_items\" :  10,\n",
    "    \"question\" : \"What is Napoleon's saying?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전쟁은 최후의 수단이다',\n",
       " '어떤 사회에도 자유가 필요하다',\n",
       " '지도자는 힘을 보여줘야 한다',\n",
       " '우리는 시련을 극복해야 한다',\n",
       " '평화는 유지되기 위해 계속해서 싸워야 한다']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"max_items\" :  10,\n",
    "    \"question\" : \"나폴레옹의 명언은 무엇인가?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
